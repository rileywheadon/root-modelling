{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e1007c3-f327-44e8-a915-b063e7e09b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from numba import njit\n",
    "from scipy.optimize import minimize, Bounds\n",
    "from scipy.stats.qmc import Sobol\n",
    "from sympy import symbols, solve, lambdify\n",
    "from prototypefour import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce8cbb1e-a21e-4efc-9f95-2a816bbf14c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.json\") as f:\n",
    "    POSITION, LENGTH, BES1, CPD, ROT3, AUXIN = map(np.array, json.load(f).values())\n",
    "\n",
    "# Define time to position and position to time functions\n",
    "time_to_position = np.poly1d(np.polyfit(POSITION[:, 0], POSITION[:, 1], 4))\n",
    "position_to_time = np.poly1d(np.polyfit(POSITION[:, 1], POSITION[:, 0], 4))\n",
    "\n",
    "# Define the time and vectors\n",
    "STEP = 0.01\n",
    "vT = np.arange(0, 18 + STEP, STEP)\n",
    "vP = time_to_position(vT)\n",
    "\n",
    "# Remove outliers from the BES1 data\n",
    "idx = np.where(BES1[:, 1] < 100)\n",
    "BES1 = BES1[idx]\n",
    "\n",
    "# Filter the data to only include positions between 150 and 600um\n",
    "# Transform the data to be in terms of time\n",
    "# Also divide by 100 so that the numerics of the model are less erratic\n",
    "def filter_transform(data):\n",
    "    idx = np.where((data[:, 0] > 150) & (data[:, 0] < 600))\n",
    "    data = data[idx]\n",
    "    data[:, 0] = position_to_time(data[:, 0])\n",
    "    data[:, 1] = data[:, 1] / 100\n",
    "    return data\n",
    "\n",
    "BES1 = filter_transform(BES1)\n",
    "LENGTH = filter_transform(LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fd9a18f-506f-4f67-aaa3-1d6cafdb6a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(config):\n",
    "\n",
    "    # Define parameters and variables\n",
    "    params = symbols('c_max p q g_B g_C')\n",
    "    c_max, p, q, g_B, g_C = params\n",
    "\n",
    "    # Define fixed parameters from prototype-4a\n",
    "    s_0, s_in, s_out, s_C = 0.0517, 0.0157, 0, 0\n",
    "\n",
    "    # Define the symbols representing hormone levels\n",
    "    B, S, C, L = symbols('B S C L')\n",
    "\n",
    "    # Construct some expressions based on the configuration\n",
    "    scaled, tfbs = config\n",
    "    L_1 = L if scaled else 1\n",
    "    L_2 = 1 + (g_C * C / L) if tfbs else 1\n",
    "\n",
    "    # Write down the equations\n",
    "    signal_equation = s_in * (1 + s_C * C) * B - s_out * S\n",
    "    clasp_equation = c_max - p * (1 + q * S) * C\n",
    "    length_equation = (g_B * S * L_1) / L_2\n",
    "\n",
    "    # Lambdify the equations\n",
    "    dS = njit(lambdify([*params, B, S, C], signal_equation))\n",
    "    dC = njit(lambdify([*params, S, C], clasp_equation))\n",
    "    dL = njit(lambdify([*params, S, C, L], length_equation))\n",
    "\n",
    "    # Return the list of lambda functions\n",
    "    return [dS, dC, dL]\n",
    "\n",
    "# Create the configuration tuples and descriptions\n",
    "config_space = [(False, False), (True, False), (False, True), (True, True)]\n",
    "descriptions = [\"Base-Model\", \"L-Scaled\", \"TFBs\", \"TFBs, L-Scaled\"]\n",
    "\n",
    "# Create the simulation tuples (description, funcs)\n",
    "simulations = [(config, description, setup(config)) for config, description in zip(config_space, descriptions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b001db5-1cd0-45a7-bcdc-ae85b4c03f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the RSS of a trial run given a vector of predictions (result) and observed (data)    \n",
    "@njit\n",
    "def RSS(data, result):\n",
    "    predicted = np.interp(data[:, 0], vT, result)\n",
    "    observed = data[:, 1]\n",
    "    residuals = predicted - observed\n",
    "    rss = np.sum(np.square(residuals))\n",
    "    return rss / residuals.shape[0]\n",
    "\n",
    "# Run a complete simulation\n",
    "@njit\n",
    "def simulate_cell(params, dS, dC, dL):\n",
    "\n",
    "    c_max, p, q, g_B, g_C = params\n",
    "    s_0, s_in, s_out, s_C = 0.0517, 0.0157, 0, 0\n",
    "    \n",
    "    vB = get_br(vP, CPD, ROT3)\n",
    "    vS, s = np.array([np.float64(x) for x in range(0)]), s_0\n",
    "    vC, c = np.array([np.float64(x) for x in range(0)]), 1\n",
    "    vL, l = np.array([np.float64(x) for x in range(0)]), LENGTH[0][1]\n",
    "    \n",
    "    for b in vB:\n",
    "        s = s + dS(c_max, p, q, g_B, g_C, b, s, c) * STEP\n",
    "        c = c + dC(c_max, p, q, g_B, g_C, s, c) * STEP\n",
    "        l = l + dL(c_max, p, q, g_B, g_C, s, c, l) * STEP\n",
    "        \n",
    "        vS = np.append(vS, s)\n",
    "        vC = np.append(vC, c)\n",
    "        vL = np.append(vL, l)\n",
    "\n",
    "    return [vB, vS, vC, vL], RSS(LENGTH, vL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca70213-9bab-4a03-8902-9a3c8739aa6d",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b081f76-7a6a-445d-8e36-1a7b51cb40b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base-Model\n",
      "Success:  True `gtol` termination condition is satisfied.\n",
      "Params:  [0.5, 0.5, 0.5, 0.1119, 0.5]\n",
      "Length Error:  54.6697\n",
      "First Order Sensitivities:  [0.0, 0.0, 0.0, 1.2873, 0.0]\n",
      "L-Scaled\n",
      "Success:  True `gtol` termination condition is satisfied.\n",
      "Params:  [0.5, 0.5, 0.5, 0.4988, 0.5]\n",
      "Length Error:  11.8079\n",
      "First Order Sensitivities:  [0.0, 0.0, 0.0, 1.2205, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/plant-growth/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:231: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFBs\n",
      "Success:  True `gtol` termination condition is satisfied.\n",
      "Params:  [0.0001, 0.1288, 0.9869, 0.2418, 0.9953]\n",
      "Length Error:  2.3781\n",
      "First Order Sensitivities:  [0.0048, 0.1453, 0.0269, 0.6148, 0.5055]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/plant-growth/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:231: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFBs, L-Scaled\n",
      "Success:  True `gtol` termination condition is satisfied.\n",
      "Params:  [0.0215, 0.8214, 0.513, 0.4988, 0.0]\n",
      "Length Error:  11.808\n",
      "First Order Sensitivities:  [0.0007, 0.0146, 0.0028, 0.2993, 0.0477]\n"
     ]
    }
   ],
   "source": [
    "bounds = np.array([\n",
    "    [0, 1],    # c_max\n",
    "    [0, 1],    # p\n",
    "    [0, 1],    # q\n",
    "    [0, 1],    # g_B\n",
    "    [0, 1],    # g_C\n",
    "])\n",
    "\n",
    "params = np.array([0.5, 0.5, 0.5, 0.5, 0.5])\n",
    "\n",
    "results = []\n",
    "for sim in simulations:\n",
    "\n",
    "    config, description, (dS, dC, dL) = sim\n",
    "\n",
    "    # Define the cost function\n",
    "    @njit\n",
    "    def cost(params):\n",
    "        data, error = simulate_cell(params, dS, dC, dL)\n",
    "        return error\n",
    "\n",
    "    # Find the parameters of best fit\n",
    "    fit = minimize(\n",
    "        cost, \n",
    "        params, \n",
    "        method = \"trust-constr\",\n",
    "        bounds = bounds, \n",
    "        options = {\"maxiter\": 50000}\n",
    "    )\n",
    "    \n",
    "    # Run a simulation with the optimal parameters\n",
    "    data, error = simulate_cell(fit.x, dS, dC, dL)\n",
    "    results.append((description, data, error))\n",
    "\n",
    "    # Run a sensitivity analysis\n",
    "    fos, tei = quasi_monte_carlo(8, 5, bounds, cost)\n",
    "        \n",
    "    # Log the simulation\n",
    "    print(description)\n",
    "    print(\"Success: \", fit.success, fit.message)\n",
    "    print(\"Params: \", [round(n, 4) for n in fit.x])\n",
    "    print(\"Length Error: \", round(error * 10000, 4))\n",
    "    print(\"First Order Sensitivities: \", [round(n, 4) for n in fos])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd8c8b-359f-4f7d-81d3-ef7f10ee7c0a",
   "metadata": {},
   "source": [
    "## Mutant Roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f0f5c87-5434-4089-ad02-e3f0c3da23f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a mutant\n",
    "def simulate_mutant(params, dS, dC, dL, mutant):\n",
    "\n",
    "    c_max, p, q, g_B, g_C = params\n",
    "    s_0, s_in, s_out, s_C, c_0 = 0.0517, 0.0157, 0, 0, 1\n",
    "\n",
    "    match mutant:\n",
    "        case \"CLASP\":\n",
    "            c_0 = 0\n",
    "            dC = lambda c_max, p, q, g_B, g_C, s, c : 0\n",
    "        case \"BRIN\":\n",
    "            q = 0\n",
    "        case \"TORIN2\":\n",
    "            s_in = 0.01\n",
    "            dS = lambda c_max, p, q, g_B, g_C, b, s, c : s_in * b - s_out * s\n",
    "    \n",
    "    vB = get_br(vP, CPD, ROT3)\n",
    "    vS, s = np.array([np.float64(x) for x in range(0)]), s_0\n",
    "    vC, c = np.array([np.float64(x) for x in range(0)]), c_0\n",
    "    vL, l = np.array([np.float64(x) for x in range(0)]), LENGTH[0][1]\n",
    "    \n",
    "    for b in vB:\n",
    "        s = s + dS(c_max, p, q, g_B, g_C, b, s, c) * STEP\n",
    "        c = c + dC(c_max, p, q, g_B, g_C, s, c) * STEP\n",
    "        l = l + dL(c_max, p, q, g_B, g_C, s, c, l) * STEP\n",
    "        vS = np.append(vS, s)\n",
    "        vC = np.append(vC, c)\n",
    "        vL = np.append(vL, l)\n",
    "\n",
    "    return [vB, vS, vC, vL]\n",
    "\n",
    "# Simulate all four root types\n",
    "mutants = []\n",
    "for root_type in [\"Wild\", \"CLASP\", \"BRIN\", \"TORIN2\"]:\n",
    "    data = simulate_mutant(params, dS, dC, dL, root_type)\n",
    "    mutants.append((root_type, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c70be-3f90-4fae-aef8-108bd572278d",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d06f6a-550b-4801-8f44-d92047528676",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['font.size'] = 22\n",
    "mpl.rcParams['figure.figsize'] = (10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d83a10-27cc-4abe-a6ad-61d2d281ac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(data, desc):\n",
    "    \n",
    "    vB, vS, vC, vL = data\n",
    "    fig, (a1, a2, a3) = plt.subplots(nrows = 3, ncols = 1, sharex = True)\n",
    "    \n",
    "    a1.set_title(desc)\n",
    "    a1.plot(vT, vS, color = \"orange\", label = \"Predicted BES1\")\n",
    "    a1.scatter(BES1[:, 0], BES1[:, 1], label = \"Observed BES1\")\n",
    "    a1.set_ylabel(\"BES1 Signalling (au)\")\n",
    "    a1.legend()\n",
    "\n",
    "    a2.plot(vT, vC, color = \"orange\", label = \"Predicted CLASP\")\n",
    "    a2.set_ylabel(\"CLASP (au)\")\n",
    "    a2.legend()\n",
    "    \n",
    "    a3.plot(vT, vL, color = \"orange\", label = \"Prediced Lengths\")\n",
    "    a3.scatter(LENGTH[:, 0], LENGTH[:, 1], label = \"Mean Observed Lengths\")\n",
    "    a3.set_xlabel(\"Time (h)\")\n",
    "    a3.set_ylabel(r\"Length ($\\mu$m)\")\n",
    "    a3.legend()\n",
    "    \n",
    "    fig.savefig(f\"img/prototype-4c-{desc}.png\", bbox_inches = \"tight\")\n",
    "\n",
    "for desc, data, errors in results:\n",
    "    plot_model(data, desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c781e781-83a1-45c9-8db0-bc80cd55c056",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((a1, a2), (a3, a4)) = plt.subplots(nrows = 2, ncols = 2, sharex = True)\n",
    "fig.tight_layout()\n",
    "\n",
    "for (desc, data, errors), ax in zip(results, (a1, a2, a3, a4)):\n",
    "    vB, vS, vC, vL = data\n",
    "    \n",
    "    ax.set_title(desc)\n",
    "    ax.plot(vT, vL, color = \"orange\", label = \"Prediced Lengths\")\n",
    "    ax.scatter(LENGTH[:, 0], LENGTH[:, 1], label = \"Mean Observed Lengths\")\n",
    "    ax.set_ylabel(\"Length (100um)\")\n",
    "    ax.set_ylim((0, 1))\n",
    "\n",
    "a3.set_xlabel(\"Time (h)\")\n",
    "a4.set_xlabel(\"Time (h)\")\n",
    "fig.savefig(\"img/prototype-4c-comparison\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f23b448-6abc-4994-a61d-f76887b0af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mutant data\n",
    "fig, ((a1, a2), (a3, a4)) = plt.subplots(nrows = 2, ncols = 2, sharex = True)\n",
    "fig.tight_layout()\n",
    "\n",
    "for (desc, data), ax in zip(mutants, (a1, a2, a3, a4)):\n",
    "    vB, vS, vC, vL = data\n",
    "    \n",
    "    ax.set_title(desc)\n",
    "    ax.plot(vT, vL, color = \"orange\", label = \"Prediced Lengths\")\n",
    "    ax.scatter(LENGTH[:, 0], LENGTH[:, 1], label = \"Mean Observed Lengths\")\n",
    "    ax.set_ylabel(\"Length (100um)\")\n",
    "    ax.set_ylim((0, 1))\n",
    "\n",
    "a3.set_xlabel(\"Time (h)\")\n",
    "a4.set_xlabel(\"Time (h)\")\n",
    "fig.savefig(\"img/prototype-4c-mutants\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3b47d6-798e-4759-b522-543c8f49a340",
   "metadata": {},
   "source": [
    "## Other Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd24070a-1c16-4260-9579-725c7919d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the transformed and filtered length data\n",
    "plt.scatter(LENGTH[:, 0], LENGTH[:, 1], label = \"Mean Lengths\")\n",
    "plt.title(\"Time vs. Mean Cell Length\")\n",
    "plt.xlabel(\"Time (h)\")\n",
    "plt.ylabel(\"Mean Length (um\")\n",
    "plt.legend()\n",
    "plt.savefig(\"img/prototype-4b-lengths.png\", bbox_inches = \"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
